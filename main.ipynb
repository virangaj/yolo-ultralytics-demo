{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "model = YOLO('yolov8n.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.train(data='config.yaml', epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val()  # evaluate model performance on the validation set\n",
    "results = model(\"F:/AI ML DL Projects/Supports/Yolo object detection/dataset/data/images/val/134.jpg\")  # predict on an image\n",
    "path = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics.utils.plotting import Annotator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"F:\\AI ML DL Projects\\Supports\\yolo-ultralytics-demo\\DJI_20221113125848_0054.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modal\n",
    "model_100 = YOLO('F:/AI ML DL Projects/Supports/yolo-ultralytics-demo/runs/detect/train_size10_epoch100/weights/best.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading F:\\AI ML DL Projects\\Supports\\yolo-ultralytics-demo\\runs\\detect\\train_size10_epoch100\\weights\\best.onnx for ONNX Runtime inference...\n",
      "\n",
      "0: 640x640 9 coconuts, 3 palms, 491.6ms\n",
      "Speed: 5.0ms preprocess, 491.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results_100 = model_100.predict(image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'coconut', 1: 'palm'}\n",
       " orig_img: array([[[ 62,  76,  88],\n",
       "         [ 51,  65,  77],\n",
       "         [ 47,  61,  73],\n",
       "         ...,\n",
       "         [ 58,  84,  61],\n",
       "         [ 67,  93,  70],\n",
       "         [ 61,  87,  64]],\n",
       " \n",
       "        [[ 65,  79,  91],\n",
       "         [ 59,  73,  85],\n",
       "         [ 56,  70,  82],\n",
       "         ...,\n",
       "         [ 68,  94,  71],\n",
       "         [ 71,  97,  74],\n",
       "         [ 64,  90,  67]],\n",
       " \n",
       "        [[ 59,  75,  87],\n",
       "         [ 60,  76,  88],\n",
       "         [ 65,  81,  93],\n",
       "         ...,\n",
       "         [ 82, 109,  89],\n",
       "         [ 90, 117,  97],\n",
       "         [ 89, 116,  96]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 45,  59,  53],\n",
       "         [ 43,  57,  51],\n",
       "         [ 44,  58,  52],\n",
       "         ...,\n",
       "         [ 28,  37,  27],\n",
       "         [ 34,  43,  33],\n",
       "         [ 37,  46,  36]],\n",
       " \n",
       "        [[ 47,  61,  55],\n",
       "         [ 48,  62,  56],\n",
       "         [ 50,  64,  58],\n",
       "         ...,\n",
       "         [ 32,  41,  31],\n",
       "         [ 37,  46,  36],\n",
       "         [ 37,  46,  36]],\n",
       " \n",
       "        [[ 47,  61,  55],\n",
       "         [ 54,  68,  62],\n",
       "         [ 59,  73,  67],\n",
       "         ...,\n",
       "         [ 33,  42,  32],\n",
       "         [ 34,  43,  33],\n",
       "         [ 29,  38,  28]]], dtype=uint8)\n",
       " orig_shape: (5460, 8192)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 5.002260208129883, 'inference': 491.6362762451172, 'postprocess': 1.0006427764892578}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'xyxy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\AI ML DL Projects\\Supports\\yolo-ultralytics-demo\\main.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/AI%20ML%20DL%20Projects/Supports/yolo-ultralytics-demo/main.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m img_result \u001b[39min\u001b[39;00m results_100\u001b[39m.\u001b[39;49mxyxy[\u001b[39m0\u001b[39m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/AI%20ML%20DL%20Projects/Supports/yolo-ultralytics-demo/main.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     img \u001b[39m=\u001b[39m img_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/AI%20ML%20DL%20Projects/Supports/yolo-ultralytics-demo/main.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     img\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'xyxy'"
     ]
    }
   ],
   "source": [
    "for img_result in results_100.xyxy[0]:\n",
    "    img = img_result.get(\"img\")\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_20 = YOLO('F:/AI ML DL Projects/Supports/yolo-ultralytics-demo/runs/detect/train_size10_epoch20/weights/best.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading F:\\AI ML DL Projects\\Supports\\yolo-ultralytics-demo\\runs\\detect\\train_size10_epoch20\\weights\\best.onnx for ONNX Runtime inference...\n",
      "\n",
      "0: 640x640 (no detections), 543.1ms\n",
      "Speed: 5.0ms preprocess, 543.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results_20 = model_20.predict(image) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
