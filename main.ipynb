{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "model = YOLO('yolov8n.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.train(data='config.yaml', epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val()  # evaluate model performance on the validation set\n",
    "results = model(\"F:/AI ML DL Projects/Supports/Yolo object detection/dataset/data/images/val/134.jpg\")  # predict on an image\n",
    "path = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics.utils.plotting import Annotator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_10 = cv2.imread(\"F:/AI ML DL Projects/Supports/yolo-ultralytics-demo/dataset/data/images10/val/155.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modal\n",
    "model_10 = YOLO('F:/AI ML DL Projects/Supports/yolo-ultralytics-demo/runs/detect/train_size10_epoch100/weights/best.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 95 coconuts, 13 palms, 636.1ms\n",
      "Speed: 5.0ms preprocess, 636.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "3 labels saved to runs\\detect\\predict\\labels\n"
     ]
    }
   ],
   "source": [
    "results_10 = model_10.predict(image_10, save=True, save_txt=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_15 = cv2.imread(\"F:/AI ML DL Projects/Supports/yolo-ultralytics-demo/dataset/data/images15/val/155.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modal\n",
    "model_15 = YOLO('F:/AI ML DL Projects/Supports/yolo-ultralytics-demo/runs/detect/train_size15_epoch125/weights/best.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 71 coconuts, 10 palms, 518.9ms\n",
      "Speed: 6.0ms preprocess, 518.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "2 labels saved to runs\\detect\\predict\\labels\n"
     ]
    }
   ],
   "source": [
    "results_15 = model_15.predict(image_15, save=True, save_txt=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_20 = cv2.imread(\"F:/AI ML DL Projects/Supports/yolo-ultralytics-demo/dataset/data/images/val/155.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modal\n",
    "model_20 = YOLO('F:/AI ML DL Projects/Supports/yolo-ultralytics-demo/runs/detect/train_size20_epoch125/weights/best.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 82 coconuts, 11 palms, 525.6ms\n",
      "Speed: 7.0ms preprocess, 525.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "1 label saved to runs\\detect\\predict\\labels\n"
     ]
    }
   ],
   "source": [
    "results_20 = model_20.predict(image_20, save=True, save_txt=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'coconut', 1: 'palm'}\n",
       " orig_img: array([[[ 50,  70,  57],\n",
       "         [ 70,  90,  77],\n",
       "         [ 74,  91,  80],\n",
       "         ...,\n",
       "         [ 63,  70,  65],\n",
       "         [ 39,  46,  39],\n",
       "         [ 43,  50,  43]],\n",
       " \n",
       "        [[ 53,  73,  60],\n",
       "         [ 57,  77,  64],\n",
       "         [ 66,  83,  72],\n",
       "         ...,\n",
       "         [ 56,  63,  58],\n",
       "         [ 36,  43,  36],\n",
       "         [ 38,  45,  38]],\n",
       " \n",
       "        [[ 64,  81,  70],\n",
       "         [ 71,  88,  77],\n",
       "         [ 58,  74,  63],\n",
       "         ...,\n",
       "         [ 76,  86,  80],\n",
       "         [ 60,  68,  61],\n",
       "         [ 50,  58,  51]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 53,  80,  71],\n",
       "         [ 73, 100,  91],\n",
       "         [ 68,  94,  88],\n",
       "         ...,\n",
       "         [ 66,  78,  78],\n",
       "         [ 43,  59,  58],\n",
       "         [ 47,  63,  62]],\n",
       " \n",
       "        [[ 62,  87,  77],\n",
       "         [ 52,  77,  67],\n",
       "         [ 43,  67,  59],\n",
       "         ...,\n",
       "         [ 47,  61,  57],\n",
       "         [ 61,  75,  73],\n",
       "         [ 64,  78,  76]],\n",
       " \n",
       "        [[ 50,  75,  65],\n",
       "         [ 46,  71,  61],\n",
       "         [ 49,  73,  65],\n",
       "         ...,\n",
       "         [ 39,  53,  49],\n",
       "         [ 43,  58,  54],\n",
       "         [ 33,  48,  44]]], dtype=uint8)\n",
       " orig_shape: (546, 819)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 4.000186920166016, 'inference': 491.61529541015625, 'postprocess': 2.0017623901367188}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
